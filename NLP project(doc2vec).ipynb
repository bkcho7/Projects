{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('full_data_joined_attr_processed_1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107791, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get document vector using gensim doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [teah, stretch-silk, camisole, beige, stretch-...\n",
       "1       [layered, velvet, mini, dress, black, velvet, ...\n",
       "2       [faux-leather, pleated, midi, skirt, accordion...\n",
       "3       [parker, logo-embellished, snake-effect, leath...\n",
       "4       [silk-crepe, midi, dress, black, silk-crepe, c...\n",
       "                              ...                        \n",
       "3670    [micro, twill, pull, pant, casual, trouser, cu...\n",
       "3671    [brushed, twill, crop, wide, leg, pant, brushe...\n",
       "3672    [slim, crop, pant, tailored, soft, dense, knit...\n",
       "3673    [camo, print, silk, skirt, flatlock-stitched, ...\n",
       "3674    [stretch, pima, cotton, baby, tee, made, atm, ...\n",
       "Length: 3675, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique data from our cleaned data description, details, etc.\n",
    "doc=pd.Series(data['final'].unique()).str.split()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim and get document vector\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(doc)]\n",
    "model = Doc2Vec(documents, vector_size=50, window=4, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get doc2vec\n",
    "for sentence in doc:\n",
    "    vec=model.infer_vector(sentence).reshape(1, -1)\n",
    "    doc_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.DataFrame({\n",
    "            'final': data['final'].unique(),\n",
    "            'doc': doc,\n",
    "            'doc_vec': doc_vec\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original data to link all the rows with doc2vec\n",
    "data=pd.merge(data, vec_df, on='final', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification model_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one hot encoded file \n",
    "style_file=pd.read_csv('style_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_file=style_file.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all style tags\n",
    "style_cat=['androgynous','athleisure', 'boho','businesscasual','casual','classic','edgy','glam','modern','retro','romantic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_file['doc_vec']=data['doc_vec'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for androgynous: 0.823766364551863\n",
      "accuracy for athleisure: 0.932527693856999\n",
      "accuracy for boho: 0.8831822759315207\n",
      "accuracy for businesscasual: 0.7109768378650554\n",
      "accuracy for casual: 0.6626384692849949\n",
      "accuracy for classic: 0.6354481369587109\n",
      "accuracy for edgy: 0.7955689828801611\n",
      "accuracy for glam: 0.9073514602215509\n",
      "accuracy for modern: 0.5861027190332326\n",
      "accuracy for retro: 0.9365558912386707\n",
      "accuracy for romantic: 0.8660624370594159\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression model for each tag in style\n",
    "style_acc=[]\n",
    "for style in style_cat:\n",
    "    new_style=style_file.sort_values(by=['product_id',style], ascending=False).drop_duplicates(subset='product_id',keep='first')\n",
    "    y=new_style[style]\n",
    "    model=LogisticRegression()\n",
    "    new_style[\"TARGET\"] = y\n",
    "    train_df, test_df = train_test_split(new_style)\n",
    "    X_train=train_df['doc_vec'].tolist()\n",
    "    X_test=test_df['doc_vec'].tolist()\n",
    "    y_train = train_df[\"TARGET\"]\n",
    "    y_test = test_df[\"TARGET\"]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'accuracy for {style}: {np.mean(y_pred == y_test)}')\n",
    "    style_acc.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. model_embellishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one hot encoded file \n",
    "embel_file=pd.read_csv('embel_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embel_file=embel_file.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all embellishment tags\n",
    "embel_cat=['buckles','embroidery','fringe','lace','mesh','ruffles','sequins','studs','trim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embel_file['doc_vec']=data['doc_vec'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for buckles: 0.9969788519637462\n",
      "accuracy for embroidery: 0.9949647532729103\n",
      "accuracy for fringe: 0.998992950654582\n",
      "accuracy for lace: 0.998992950654582\n",
      "accuracy for mesh: 0.9979859013091642\n",
      "accuracy for ruffles: 0.9909365558912386\n",
      "accuracy for sequins: 1.0\n",
      "accuracy for studs: 0.998992950654582\n",
      "accuracy for trim: 0.998992950654582\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression model for each tag in embellishment\n",
    "embel_acc=[]\n",
    "for embel in embel_cat:\n",
    "    new_embel=embel_file.sort_values(by=['product_id',embel], ascending=False).drop_duplicates(subset='product_id',keep='first')\n",
    "    y=new_embel[embel]\n",
    "    model=LogisticRegression()\n",
    "    new_embel[\"TARGET\"] = y\n",
    "    train_df, test_df = train_test_split(new_embel)\n",
    "    X_train=train_df['doc_vec'].tolist()\n",
    "    X_test=test_df['doc_vec'].tolist()\n",
    "    y_train = train_df[\"TARGET\"]\n",
    "    y_test = test_df[\"TARGET\"]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'accuracy for {embel}: {np.mean(y_pred == y_test)}')\n",
    "    embel_acc.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.model_occasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one hot encoded file \n",
    "occ_file=pd.read_csv('occ_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_file=occ_file.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all occasion tags\n",
    "occ_cat=['coldweather','daytonight','nightout','vacation','weekend','work','workout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_file['doc_vec']=data['doc_vec'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for coldweather: 0.9355488418932527\n",
      "accuracy for daytonight: 0.297079556898288\n",
      "accuracy for nightout: 0.7905337361530715\n",
      "accuracy for vacation: 0.837865055387714\n",
      "accuracy for weekend: 0.2588116817724068\n",
      "accuracy for work: 0.6525679758308157\n",
      "accuracy for workout: 0.9607250755287009\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression model for each tag in occasion\n",
    "occ_acc=[]\n",
    "for occ in occ_cat:\n",
    "    new_occ=occ_file.sort_values(by=['product_id',occ], ascending=False).drop_duplicates(subset='product_id',keep='first')\n",
    "    y=new_occ[occ]\n",
    "    model=LogisticRegression()\n",
    "    new_occ[\"TARGET\"] = y\n",
    "    train_df, test_df = train_test_split(new_occ)\n",
    "    X_train=train_df['doc_vec'].tolist()\n",
    "    X_test=test_df['doc_vec'].tolist()\n",
    "    y_test = test_df[\"TARGET\"]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'accuracy for {occ}: {np.mean(y_pred == y_test)}')\n",
    "    occ_acc.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. model_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one hot encoded file \n",
    "cat_file=pd.read_csv('cat_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_file=cat_file.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all category tags\n",
    "cat_cat=['accessory','blazerscoatsjackets','bottom','onepiece','shoe','sweater','sweatshirthoodie','top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_file['doc_vec']=data['doc_vec'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for accessory: 0.9144008056394763\n",
      "accuracy for blazerscoatsjackets: 0.9295065458207452\n",
      "accuracy for bottom: 0.7764350453172205\n",
      "accuracy for onepiece: 0.9093655589123867\n",
      "accuracy for shoe: 0.8157099697885196\n",
      "accuracy for sweater: 0.918429003021148\n",
      "accuracy for sweatshirthoodie: 0.9617321248741189\n",
      "accuracy for top: 0.7492447129909365\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression model for each tag in category\n",
    "cat_acc=[]\n",
    "for cat in cat_cat:\n",
    "    new_cat=cat_file.sort_values(by=['product_id',cat], ascending=False).drop_duplicates(subset='product_id',keep='first')\n",
    "    y=new_cat[cat]\n",
    "    model=LogisticRegression()\n",
    "    new_cat[\"TARGET\"] = y\n",
    "    train_df, test_df = train_test_split(new_cat)\n",
    "    X_train=train_df['doc_vec'].tolist()\n",
    "    X_test=test_df['doc_vec'].tolist()\n",
    "    y_train = train_df[\"TARGET\"]\n",
    "    y_test = test_df[\"TARGET\"]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'accuracy for {cat}: {np.mean(y_pred == y_test)}')\n",
    "    cat_acc.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. model_dryclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one hot encoded file \n",
    "dry_file=pd.read_csv('dry_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_file=dry_file.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dryclean tags\n",
    "dry_cat=['yes','no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_file['doc_vec']=data['doc_vec'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for yes: 0.6696878147029205\n",
      "accuracy for no: 0.6696878147029205\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression model for each tag in dryclean\n",
    "dry_acc=[]\n",
    "for dry in dry_cat:\n",
    "    new_dry=dry_file.sort_values(by=['product_id',dry], ascending=False).drop_duplicates(subset='product_id',keep='first')\n",
    "    y=new_dry[dry]\n",
    "    model=LogisticRegression()\n",
    "    new_dry[\"TARGET\"] = y\n",
    "    train_df, test_df = train_test_split(new_dry)\n",
    "    X_train=train_df['doc_vec'].tolist()\n",
    "    X_test=test_df['doc_vec'].tolist()\n",
    "    y_train = train_df[\"TARGET\"]\n",
    "    y_test = test_df[\"TARGET\"]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'accuracy for {dry}: {np.mean(y_pred == y_test)}')\n",
    "    dry_acc.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get average accuracy for all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=style_acc+embel_acc+occ_acc+cat_acc+dry_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314689311668164"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list) / len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
